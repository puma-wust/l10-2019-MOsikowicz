{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pyro\n",
    "import torch\n",
    "import numpy as np\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import pyro.optim as optim\n",
    "import pyro.distributions as dist\n",
    "from torch.distributions import constraints\n",
    "from tqdm import tqdm\n",
    "from matplotlib import animation, rc\n",
    "from IPython.display import HTML\n",
    "import torch.nn as nn\n",
    "from functools import partial\n",
    "import pandas as pd\n",
    "from pyro.contrib.autoguide import AutoDiagonalNormal\n",
    "from pyro.infer import EmpiricalMarginal, SVI, Trace_ELBO, TracePredictive\n",
    "from pyro.distributions import Normal\n",
    "from torch.autograd import Variable\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def loadDataset(filename): \n",
    "    lines = csv.reader(open(filename)) \n",
    "    dataset = list(lines) \n",
    "    return dataset\n",
    "\n",
    "def stratifiedSplit(dataset, splits):\n",
    "    splitSets = []\n",
    "    labelsArray = []\n",
    "    for i in range(0,len(dataset)):\n",
    "        labelsArray.append(int(dataset[i][-1]))\n",
    "    skf = StratifiedKFold(n_splits=splits, shuffle=True)\n",
    "    for train_index, test_index in skf.split(dataset, labelsArray):\n",
    "        temp = []\n",
    "        for i in range(0,len(train_index)):\n",
    "            temp.append(dataset[train_index[i]])\n",
    "        splitSets.append(temp)\n",
    "        temp = []\n",
    "        for i in range(0,len(test_index)):\n",
    "            temp.append(dataset[test_index[i]])\n",
    "        splitSets.append(temp)\n",
    "    return splitSets\n",
    "\n",
    "def model(data):     \n",
    "    mean = pyro.sample('mean' , Normal(0., 1.))   \n",
    "    std = pyro.sample('std' , Normal(1., 0.5))     \n",
    "    with pyro.plate('data', len(data)):\n",
    "        data_obs = torch.from_numpy(data.astype(np.float)).type(torch.FloatTensor) \n",
    "        pyro.sample(\"obs\", Normal(mean,std),obs = data_obs)\n",
    "\n",
    "def guide(data):  \n",
    "    mean_loc =pyro.param('mean_loc', torch.tensor(0.)) \n",
    "    mean_scale = pyro.param('mean_scale', torch.tensor(1.0), constraint=constraints.positive)  \n",
    "    std_loc = pyro.param('std_loc', torch.tensor(1.),  constraint=constraints.positive) \n",
    "    std_scale = pyro.param('std_scale', torch.tensor(0.2), constraint=constraints.positive)  \n",
    "    mean = pyro.sample('mean', Normal(mean_loc, mean_scale))\n",
    "    std = pyro.sample('std', Normal(std_loc, std_scale))\n",
    "\n",
    "def infer_dist(values): #input- all values of 1 attribute for 1 class\n",
    "    pyro.clear_param_store()\n",
    "    num_iterations=1000\n",
    "    optim = pyro.optim.Adam({\"lr\": 0.01})\n",
    "    count = len(data)\n",
    "    svi = pyro.infer.SVI(model, guide, optim, loss=pyro.infer.Trace_ELBO(), num_samples=count)\n",
    "    for i in range(0,num_iterations):\n",
    "        loss = svi.step(values)\n",
    "    #for name, value in pyro.get_param_store().items():\n",
    "        #print(name, pyro.param(name))\n",
    "    return (model, svi)\n",
    "\n",
    "def separateAttributes(dataset, attributes):\n",
    "    count = len(dataset)\n",
    "    separatedDataset = np.empty((attributes, count))\n",
    "    separatedDataset.fill(0)\n",
    "    for i in range (len(dataset[0])):\n",
    "        for j in range (len(dataset)):\n",
    "            separatedDataset[i][j] = dataset[j][i]\n",
    "    return separatedDataset\n",
    "\n",
    "def separateByClass(dataset):\n",
    "    separated = {}\n",
    "    for i in range(len(dataset)):\n",
    "        vector = dataset[i]\n",
    "        if (vector[-1] not in separated):\n",
    "            separated[vector[-1]] = []\n",
    "        separated[vector[-1]].append(vector)\n",
    "    return separated\n",
    "\n",
    "def modelizeGaussian(dataset): #input: class separated 3d dataset, creates model for naive bayes classification\n",
    "    model = {}\n",
    "    count = len(dataset[1])\n",
    "    for i in range(0, len(dataset)):\n",
    "        attrArr = separateAttributes(dataset[i], len(dataset[0]))\n",
    "        temp = []\n",
    "        model[str(i)] = []\n",
    "        for j in range(0, len(dataset[1][0])-1):\n",
    "            infer_dist(attrArr[j])\n",
    "            mean = pyro.param(\"mean_loc\").item()\n",
    "            stdev = pyro.param(\"std_loc\").item()\n",
    "            if (stdev == 0):\n",
    "                stdev = 0.0001\n",
    "            temp = [mean,stdev]\n",
    "            model[str(i)].append(temp)\n",
    "            temp = []\n",
    "    return model\n",
    "\n",
    "def calculateGaussianProb(value, mean, stdev):\n",
    "    exponent = math.exp(-(math.pow(value-mean,2)/(2*math.pow(stdev,2))))\n",
    "    return (1 / (math.sqrt(2*math.pi) * stdev)) * exponent\n",
    "\n",
    "def predictClassGauss(model, instance):\n",
    "    temp = []\n",
    "    prob = 1\n",
    "    maxProb = -1\n",
    "    prediction = -1\n",
    "    for i  in range (0, len(model)): \n",
    "        for j in range (0, len(instance)-1):\n",
    "            mean = model[str(i)][j][0]\n",
    "            stdev = model[str(i)][j][1]\n",
    "            value = instance[j]\n",
    "            prob = prob*calculateGaussianProb(value, mean, stdev)\n",
    "        if(prob > maxProb):\n",
    "            maxProb = prob\n",
    "            prediction = i\n",
    "        temp.append(prob)\n",
    "        prob = 1\n",
    "    return prediction\n",
    "\n",
    "def testGauss(fileName, folds, tests):\n",
    "    dataTest = np.asarray(loadDataset(fileName)) #load  whole data for new discretizer\n",
    "    dataTest = np.asarray(dataTest).astype(np.float64)\n",
    "    data = dataTest\n",
    "    classed = separateByClass(data)\n",
    "    testCount = 0\n",
    "    totalAccuracy = 0\n",
    "    totalF1 = 0\n",
    "    totalRecall = 0\n",
    "    totalPrecision = 0\n",
    "    confMatrix = []\n",
    "    for i in range(0, len(classed)):\n",
    "        temp = []\n",
    "        for j in range (0, len(classed)):\n",
    "            temp.append(0)\n",
    "        confMatrix.append(temp)\n",
    "    while testCount < tests:\n",
    "        stratifiedSplitted = stratifiedSplit(data, folds) #to w zewnętrznej pętli testów\n",
    "        accuracy = 0\n",
    "        recall = 0\n",
    "        precision = 0\n",
    "        F1 = 0\n",
    "        foldCount = 0\n",
    "        while foldCount < folds*2:\n",
    "            trueClasses = []\n",
    "            predictedClasses = []\n",
    "            learn = stratifiedSplitted[foldCount] #to w wewnętrznej pętli przechodzenia po foldach\n",
    "            test = stratifiedSplitted[foldCount+1]\n",
    "            classed = separateByClass(data) #create separated dataset by class\n",
    "            classedLearn = separateByClass(learn)\n",
    "            model = modelizeGaussian(classedLearn) #create model for the data\n",
    "            hit = 0\n",
    "            miss = 0\n",
    "            for i in range(len(test)):\n",
    "                instance = test[i]\n",
    "                correct = instance[-1]\n",
    "                predicted = predictClassGauss(model, instance)\n",
    "                trueClasses.append(int(correct))\n",
    "                predictedClasses.append(predicted)\n",
    "                if (int(correct) == int(predicted)):\n",
    "                    hit = hit + 1\n",
    "                else:\n",
    "                    miss = miss + 1\n",
    "                confMatrix[predicted][int(correct)] += 1           \n",
    "            foldCount = foldCount + 2 #przesuń indeks zestawów learn/validate o 2\n",
    "            accuracy = accuracy + (hit/len(test))\n",
    "            recall += recall_score(trueClasses, predictedClasses, average='macro')\n",
    "            precision += precision_score(trueClasses, predictedClasses, average='macro')\n",
    "            F1 =  F1 + f1_score(trueClasses, predictedClasses, average='macro')\n",
    "        testCount = testCount + 1\n",
    "        totalAccuracy += accuracy/folds\n",
    "        totalRecall += recall/folds\n",
    "        totalPrecision += precision/folds\n",
    "        totalF1 += F1/folds\n",
    "    for i in range (0, len(confMatrix)):\n",
    "        print(confMatrix[i])\n",
    "    return [totalAccuracy/tests, totalRecall/tests, totalPrecision/tests, totalF1/tests]\n",
    "\n",
    "dataTest = np.asarray(loadDataset(\"iris.data\")) \n",
    "dataTest = np.asarray(dataTest).astype(np.float64)\n",
    "data = dataTest\n",
    "classed = separateByClass(data)\n",
    "stratifiedSplitted = stratifiedSplit(data, 2)\n",
    "trueClasses = []\n",
    "predictedClasses = []\n",
    "learn = stratifiedSplitted[0] \n",
    "test = stratifiedSplitted[1]\n",
    "classed = separateByClass(data) #create separated dataset by class\n",
    "classedLearn = separateByClass(learn)\n",
    "model = modelizeGaussian(classedLearn) #create model for the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "import math\n",
    "F1 = 0\n",
    "for i in range(len(test)):\n",
    "    instance = test[i]\n",
    "    correct = instance[-1]\n",
    "    predicted = predictClassGauss(model, instance)\n",
    "    trueClasses.append(int(correct))\n",
    "    predictedClasses.append(predicted)        \n",
    "F1 =  F1 + f1_score(trueClasses, predictedClasses, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97333333333333327"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n"
     ]
    }
   ],
   "source": [
    "print(trueClasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2]\n"
     ]
    }
   ],
   "source": [
    "print(predictedClasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
